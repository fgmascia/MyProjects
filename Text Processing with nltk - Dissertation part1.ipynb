{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting page rank using Text and Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First part of my dissertation project focused on text processing. I gather Amazon UK data regarding the Skincare market. I filtered only the page rank (target) and price and text (name + description) which will be the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset I previously cleansed\n",
    "SkinTextRed2 = pd.read_csv(\"Skincare2Yreduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 935934 entries, 0 to 935933\n",
      "Data columns (total 3 columns):\n",
      "Text     935934 non-null object\n",
      "price    935934 non-null float64\n",
      "rank     935934 non-null int64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 21.4+ MB\n"
     ]
    }
   ],
   "source": [
    "SkinTextRed2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by text to delete duplicates, keeping the mean for price and rank\n",
    "SkinTextRed=SkinTextRed2.groupby(['Text'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25293 entries, 0 to 25292\n",
      "Data columns (total 3 columns):\n",
      "Text     25293 non-null object\n",
      "price    25293 non-null float64\n",
      "rank     25293 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 790.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# only 25000 left\n",
    "SkinTextRed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional cleansing needed\n",
    "SkinTextRed['Text'] = SkinTextRed['Text'].str.replace(r\"[|&•–�®∙*#]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LET'S TRY TO REMOVE STOPWORDS\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "SkinTextRed['Text'] = SkinTextRed['Text'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY STEMMING !\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "ps = PorterStemmer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_sentences(sentence):\n",
    "    tokens = sentence.split()\n",
    "    stemmed_tokens = [ps.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "SkinTextRed['TextSt'] = SkinTextRed['Text'].apply(stem_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10 pack alo pura alo vera sun lotion 200ml 10 ...\n",
       "1    10 pack alo pura alo vera sun lotion 200ml 10 ...\n",
       "2    10 pack avalon rejuv oil free moistur 50ml 10 ...\n",
       "3    10 pack avalon rejuv oil free moistur 50ml 10 ...\n",
       "4    10 pack avalon rosemari hand bodi lotion 350ml...\n",
       "Name: TextSt, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SkinTextRed['TextSt'].head()\n",
    "# IT WORKED !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23d51e83ba8>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How is the rank variable distributed?\n",
    "SkinTextRed['rank'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I label the ranks as 0 or 1 to have a binary target\n",
    "def label_rank (row):\n",
    "   if row['rank'] > 700 : #products not in the first page\n",
    "      return 0\n",
    "   if row['rank'] < 100: #product in the first page\n",
    "      return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "SkinTextRed.apply (lambda row: label_rank (row),axis=1)\n",
    "SkinTextRed['rank'] = SkinTextRed.apply (lambda row: label_rank (row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5608 entries, 9 to 25277\n",
      "Data columns (total 4 columns):\n",
      "Text      5608 non-null object\n",
      "price     5608 non-null float64\n",
      "rank      5608 non-null float64\n",
      "TextSt    5608 non-null object\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 219.1+ KB\n"
     ]
    }
   ],
   "source": [
    "SkinTextRed = SkinTextRed.dropna()\n",
    "SkinTextRed['rank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to use the text as predictor I have to Vectorize\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(SkinTextRed['TextSt'])\n",
    "X = cv.transform(SkinTextRed['TextSt'])\n",
    "X2 = SkinTextRed['price']\n",
    "y = SkinTextRed['rank']\n",
    "Y = y.reset_index()\n",
    "Y1=Y.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = pd.DataFrame(X.toarray())\n",
    "X5 = X2.reset_index()\n",
    "X6 = X5.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X9 = pd.merge(X4, X6, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert floats to int to save memory\n",
    "X9['price']=X9['price'].real.astype(int,casting='unsafe')\n",
    "Y1['rank']=Y1['rank'].real.astype(int,casting='unsafe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2945\n",
       "1    2663\n",
       "Name: rank, dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1['rank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19717</th>\n",
       "      <th>19718</th>\n",
       "      <th>19719</th>\n",
       "      <th>19720</th>\n",
       "      <th>19721</th>\n",
       "      <th>19722</th>\n",
       "      <th>19723</th>\n",
       "      <th>19724</th>\n",
       "      <th>price</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19727 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...   19717  19718  19719  19720  19721  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...       0      0      0      0      0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...       0      0      0      0      0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...       0      0      0      0      0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...       0      0      0      0      0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...       0      0      0      0      0   \n",
       "\n",
       "   19722  19723  19724  price  rank  \n",
       "0      0      0      0     64     1  \n",
       "1      0      0      0     64     1  \n",
       "2      0      0      0     58     0  \n",
       "3      0      0      0     58     0  \n",
       "4      0      0      0    106     1  \n",
       "\n",
       "[5 rows x 19727 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the sparse matrix with price so to use both in the model\n",
    "X10 = pd.merge(X9, Y1, left_index=True, right_index=True)\n",
    "X10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5608 entries, 0 to 5607\n",
      "Columns: 19727 entries, 0 to rank\n",
      "dtypes: int32(2), int64(19725)\n",
      "memory usage: 844.0 MB\n"
     ]
    }
   ],
   "source": [
    "X10.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split that keeps the original proportions.\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2,\n",
    "random_state=42)\n",
    "for train_index, test_index in split.split(X10, X10[\"rank\"]):\n",
    "  strat_train_set = X10.loc[train_index]\n",
    "  strat_test_set = X10.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate predictors and target\n",
    "train_predictors3 = strat_train_set.drop('rank', axis=1)\n",
    "train_target3 = strat_train_set['rank']\n",
    "test_predictors3 = strat_test_set.drop('rank', axis=1)\n",
    "test_target3 = strat_test_set['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    589\n",
       "1    533\n",
       "Name: rank, dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target3.value_counts()\n",
    "test_target3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.7807486631016043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.05: 0.7994652406417112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.25: 0.7932263814616756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.5: 0.7914438502673797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=1: 0.7914438502673797\n"
     ]
    }
   ],
   "source": [
    "X_train3, X_val3, y_train3, y_val3 = train_test_split(\n",
    "    train_predictors3, train_target3, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train3, y_train3)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val3, lr.predict(X_val3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[488 101]\n",
      " [131 402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       589\n",
      "           1       0.80      0.75      0.78       533\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1122\n",
      "   macro avg       0.79      0.79      0.79      1122\n",
      "weighted avg       0.79      0.79      0.79      1122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "final_model3 = LogisticRegression(C=0.05)\n",
    "final_model3.fit(train_predictors3, train_target3)\n",
    "y_pred3 = final_model3.predict(test_predictors3)  \n",
    "print(confusion_matrix(test_target3, y_pred3))  \n",
    "print(classification_report(test_target3, y_pred3)) \n",
    "# NOT SO BAD, WE CAN ASSUME THAT A PRODUCT IS 80% LIKELY TO END ON THE FIRST PAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 5000 unique products over the last 2 years, I used title, description and avgPrice to estimate which one of them is likely to be on the first page (avgRank<100 against avgRank>700). It gives us an idea if a product (title, description and price) is more related to the upper part of page rank or to the bottom part with 80% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('return', 0.6501747320672826)\n",
      "('indic', 0.5786871149832319)\n",
      "('scrub', 0.4981982564755433)\n",
      "('overviewritu', 0.47950666199779374)\n",
      "('proven', 0.4295953285777716)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model3.coef_[0]\n",
    "    )\n",
    "}\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mask', -0.5475147033290538)\n",
      "('lotion', -0.5190526917543132)\n",
      "('75', -0.47663609579005395)\n",
      "('argan', -0.4455899901678434)\n",
      "('foot', -0.3532340396232304)\n"
     ]
    }
   ],
   "source": [
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text only\n",
    "X11 = pd.merge(X4, Y1, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split that keeps the original proportions.\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2,\n",
    "random_state=42)\n",
    "for train_index, test_index in split.split(X11, X11[\"rank\"]):\n",
    "  strat_train_set = X11.loc[train_index]\n",
    "  strat_test_set = X11.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate predictors and target\n",
    "train_predictors4 = strat_train_set.drop('rank', axis=1)\n",
    "train_target4 = strat_train_set['rank']\n",
    "test_predictors4 = strat_test_set.drop('rank', axis=1)\n",
    "test_target4 = strat_test_set['rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.7620320855614974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.05: 0.7834224598930482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.25: 0.7816399286987522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.5: 0.7754010695187166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=1: 0.7762923351158645\n"
     ]
    }
   ],
   "source": [
    "X_train4, X_val4, y_train4, y_val4 = train_test_split(\n",
    "    train_predictors4, train_target4, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train4, y_train4)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val4, lr.predict(X_val4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[487 102]\n",
      " [146 387]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80       589\n",
      "           1       0.79      0.73      0.76       533\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1122\n",
      "   macro avg       0.78      0.78      0.78      1122\n",
      "weighted avg       0.78      0.78      0.78      1122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model4 = LogisticRegression(C=0.05)\n",
    "final_model4.fit(train_predictors4, train_target4)\n",
    "y_pred4 = final_model4.predict(test_predictors4)  \n",
    "print(confusion_matrix(test_target4, y_pred4))  \n",
    "print(classification_report(test_target4, y_pred4)) \n",
    "# SLIGHTLY LESS, THE PRICE IS HELPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is there a better way to combine the text vector with Price?\n",
    "- Try other algorithms.\n",
    "- How do I solve the Memory Error problem?\n",
    "- Suggested reading on text analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
